{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MNIST(\"~/Developer/data\", train=True, transform=T.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flat = data.data.view(-1, 28 * 28).float()\n",
    "data_flat -= data_flat.mean()\n",
    "data_flat /= data_flat.std()\n",
    "eigvals, eigvecs = torch.linalg.eigh(data_flat.T @ data_flat)\n",
    "\n",
    "# plot the largest 5 eigenvectors\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i in range(5):\n",
    "    axs[i].imshow(eigvecs[:, -i-1].view(28, 28))\n",
    "    axs[i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 10\n",
    "data_compressed = data_flat @ eigvecs[:, -n_dim:]\n",
    "full_mnist = TensorDataset(data_compressed, data.targets)\n",
    "dataset_train = Subset(full_mnist, np.arange(512))\n",
    "dataset_test = Subset(full_mnist, np.arange(512, 1024))\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_train, batch_size=64, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable-Baselines 3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "\n",
    "import stable_baselines3 as sb3\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkTrainingEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    A meta-learning environment for training neural networks.\n",
    "    The observation is given by the state_dict of the model.\n",
    "    Each parameter is an agent, and the action space is the same as the observation space.\n",
    "    The environment is episodic, and the episode ends when the model has been trained for a\n",
    "    specified number of epochs.\n",
    "\n",
    "    Args:\n",
    "        init_model: A function that returns a new model.\n",
    "        dataloader: A dataloader that returns a batch of data for evaluation.\n",
    "        loss_fn: The loss function to use for training. Should return the _sum_ of the losses across the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"name\": \"meta_learning\",\n",
    "        \"render_modes\": [],\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        init_model: Callable[[], nn.Module],\n",
    "        dataloader: DataLoader,\n",
    "        loss_fn: nn.Module,\n",
    "        max_cycles: int = 200,\n",
    "        action_bounds=1e6\n",
    "    ):\n",
    "        self.init_model = init_model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.dataloader = dataloader\n",
    "        self.max_cycles = max_cycles\n",
    "\n",
    "        # get dummy model to get the possible agents.\n",
    "        state_dict = init_model().state_dict()\n",
    "        self.weight_keys = list(state_dict.keys())\n",
    "\n",
    "        # the action spaces are identical to the state spaces\n",
    "        self.action_shape = state_dict[self.weight_keys[0]].shape\n",
    "        assert all([v.shape == self.action_shape for v in state_dict.values()])\n",
    "        space = Box(-action_bounds, action_bounds, shape=(len(self.weight_keys),) + self.action_shape)\n",
    "        self.observation_space = space\n",
    "        self.action_space = space\n",
    "\n",
    "        del state_dict\n",
    "\n",
    "    def seed(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def to_state_dict(self, actions: np.ndarray):\n",
    "        actions = actions.reshape(len(self.weight_keys), *self.action_shape)\n",
    "        return {k: torch.from_numpy(action) for k, action in zip(self.weight_keys, actions)}\n",
    "\n",
    "    def get_obs(self):\n",
    "        state_dict = self.model.state_dict()\n",
    "        return np.stack([state_dict[k] for k in self.weight_keys])\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        seed: Optional[int] = None,\n",
    "        return_info: bool = False,\n",
    "        options: Optional[dict] = None,\n",
    "    ):\n",
    "        self.model = self.init_model()\n",
    "        self.model.eval()\n",
    "        self.epoch = 0\n",
    "\n",
    "        return self.get_obs()\n",
    "\n",
    "    def step(self, actions: np.ndarray):\n",
    "        actions = self.to_state_dict(actions)\n",
    "        self.model.load_state_dict(actions)\n",
    "        test_loss = self.eval()\n",
    "        done = self.epoch >= self.max_cycles\n",
    "        self.epoch += 1\n",
    "        return (\n",
    "            self.get_obs(),\n",
    "            -test_loss,\n",
    "            done,\n",
    "            {},\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def eval(self):\n",
    "        \"\"\"\n",
    "        Calculate total error across the given dataloader.\n",
    "        \"\"\"\n",
    "        test_loss = 0\n",
    "        for x, y in self.dataloader:\n",
    "            out = self.model(x)\n",
    "            loss = self.loss_fn(out, y)\n",
    "            test_loss += loss.item()\n",
    "        return test_loss / len(self.dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = lambda: nn.Linear(10, 10, bias=False)\n",
    "deep_model = lambda: nn.Sequential(\n",
    "    layer(),\n",
    "    nn.ReLU(True),\n",
    "    layer(),\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "env = NeuralNetworkTrainingEnv(layer, dataloader_train, loss_fn)\n",
    "env.action_space.shape, env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, loader, get_acc=False, n_epochs=100):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    losses = []\n",
    "    if get_acc:\n",
    "        accuracies = []\n",
    "    for _ in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        if get_acc:\n",
    "            total_acc = 0\n",
    "        for x, y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            loss_sum = loss_fn(y_hat, y)\n",
    "            total_loss += loss_sum.item()\n",
    "            loss = loss_sum / len(y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if get_acc:\n",
    "                total_acc += (y_hat.argmax(dim=-1) == y).sum().item()\n",
    "            \n",
    "        losses.append(total_loss / len(loader.dataset))\n",
    "        if get_acc:\n",
    "            accuracies.append(total_acc / len(loader.dataset))\n",
    "    \n",
    "    if get_acc:\n",
    "        return losses, accuracies\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_meta(model, policy, loss_fn, loader, n_epochs=100):\n",
    "    env = NeuralNetworkTrainingEnv(lambda: model, loader, loss_fn, max_cycles=n_epochs)\n",
    "    obs = env.reset()\n",
    "    losses = []\n",
    "    for _ in range(n_epochs):\n",
    "        action, _ = policy.predict(obs, deterministic=True)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        losses.append(-reward)\n",
    "    return losses, env.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = sb3.PPO(\"MlpPolicy\", env, verbose=1, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.learn(total_timesteps=1024, progress_bar=True, tb_log_name=\"ppo_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.save(\"saved_models/ppo_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses_train = train(layer(), loss_fn, loader_train)\n",
    "losses_meta_train, train_model = train_meta(layer(), policy, loss_fn, dataloader_train)\n",
    "losses_meta_test, test_model = train_meta(layer(), policy, loss_fn, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataset_train[:]\n",
    "nn.CrossEntropyLoss(reduction=\"sum\")(train_model(X), y) / 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((eigvecs[:, -n_dim:] @ X).reshape(28, 28), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(np.arange(100), losses, label=\"Gradient Descent Learning\")\n",
    "plt.scatter(np.arange(100), losses_meta_train, label=\"Meta-RL Learning (Train)\")\n",
    "plt.scatter(np.arange(100), losses_meta_test, label=\"Meta-RL Learning (Test)\")\n",
    "plt.title(\"Training losses using Meta-RL-Optimization on MNIST \\n after 2048 steps of meta training\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Cross-entropy loss with target labels\")\n",
    "plt.legend()\n",
    "plt.savefig(\"losses-mnist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(policy, env, n_eval_episodes=1, render=False, deterministic=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student-Teacher Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def gen_dataset():\n",
    "    N = 512\n",
    "    M = 100\n",
    "    D = 10\n",
    "    X = torch.randn(N, D)\n",
    "    grounded = nn.Sequential(\n",
    "        nn.Linear(D, M),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(M, D),\n",
    "        nn.ReLU(True),\n",
    "    ).eval()\n",
    "    for p in grounded.parameters():\n",
    "        p.normal_(0, 1)\n",
    "    y = grounded(X)\n",
    "\n",
    "    return TensorDataset(X, y)\n",
    "\n",
    "dataloader_teacher = DataLoader(gen_dataset(), batch_size=64, shuffle=True)\n",
    "testloader_teacher = DataLoader(gen_dataset(), batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "env = NeuralNetworkTrainingEnv(deep_model, dataloader_teacher, mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_teacher = sb3.PPO(\"MlpPolicy\", env, verbose=1, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_teacher.learn(total_timesteps=1024, progress_bar=True, tb_log_name=\"ppo_teacher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = train(layer(), mse_loss, dataloader_teacher)\n",
    "losses_meta_train, train_model = train_meta(layer(), policy, mse_loss, dataloader_teacher)\n",
    "losses_meta_test, test_model = train_meta(layer(), policy, mse_loss, testloader_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(np.arange(100), losses, label=\"Gradient Descent Learning\")\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(np.arange(100), np.log(losses_meta_train), label=\"Loss on training dataset\")\n",
    "plt.scatter(np.arange(100), np.log(losses_meta_test), label=\"Loss on test dataset\")\n",
    "plt.title(\"Mean squared error using Meta-RL on teacher-student model\\nafter 2048 timesteps of meta learning\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"losses-teacher-student.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c30f2af5f468e7f5b45bcc30fca5f4886c90d54777aed916ed5f6294dfb24bf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
